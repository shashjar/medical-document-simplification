{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import Trainer, T5Tokenizer, T5ForConditionalGeneration, TrainingArguments\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"t5-wikismall-mimic-dir/checkpoint-11500\"\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "\n",
    "def summarize_text_t5(text):\n",
    "    inputs = t5_tokenizer.encode(\n",
    "        \"summarize: \" + text,\n",
    "        return_tensors='pt',\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True\n",
    "    )\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    len1 = len(inputs[0])\n",
    " \n",
    "    summary_ids = t5_model.generate(\n",
    "        inputs,\n",
    "        exponential_decay_length_penalty=((int) (len1 * 0.8), -1.05),\n",
    "        encoder_repetition_penalty=0.3,\n",
    "        no_repeat_ngram_size=4,\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        temperature=0.9,\n",
    "    )\n",
    " \n",
    "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model = t5_model.to(DEVICE)\n",
    "with open(\"metrics/sample.txt\", 'r') as f:\n",
    "    sample = [l.strip(\"\\n\") for l in f.readlines()]\n",
    "# print(sample)\n",
    "summary = [summarize_text_t5(l) for l in sample]\n",
    "for s in summary:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
